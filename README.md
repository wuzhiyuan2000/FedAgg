# FedAgg

This repository is the official Pytorch implementation DEMO of **FedAgg**:

[**Agglomerative Federated Learning: Empowering Larger Model Training via End-Edge-Cloud Collaboration**.](https://arxiv.org/abs/2312.11489) *IEEE International Conference on Computer Communications (INFOCOM)*. 2024 (Accepted)

-------
## Run this DEMO
```python main_fedagg.py```

-------

## Cite this work

```bibtex
@inproceedings{wu2024agglomerative,
  title={Agglomerative federated learning: Empowering larger model training via end-edge-cloud collaboration},
  author={Wu, Zhiyuan and Sun, Sheng and Wang, Yuwei and Liu, Min and Gao, Bo and Pan, Quyang and He, Tianliu and Jiang, Xuefeng},
  booktitle={IEEE INFOCOM 2024-IEEE Conference on Computer Communications},
  pages={131--140},
  year={2024},
  organization={IEEE}
}
```

## Related Works

[FedICT: Federated Multi-task Distillation for Multi-access Edge Computing.](https://ieeexplore.ieee.org/abstract/document/10163770/) *IEEE Transactions on Parallel and Distributed Systems (TPDS).* 2024

[FedCache: A Knowledge Cache-driven Federated Learning Architecture for Personalized Edge Intelligence.](https://ieeexplore.ieee.org/document/10420495) *IEEE Transactions on Mobile Computing (TMC)*. 2024

[Exploring the Distributed Knowledge Congruence in Proxy-data-free Federated Distillation.](https://dl.acm.org/doi/10.1145/3639369) *ACM Transactions on Intelligent Systems and Technology (TIST)*. 2024.

[FedCache 2.0: Exploiting the Potential of Distilled Data in Knowledge Cache-driven Federated Learning.](https://arxiv.org/abs/2405.13378) *arXiv preprint arXiv:2405.13378*. 2024.

[Privacy-Enhanced Training-as-a-Service for On-Device Intelligence: Concept, Architectural Scheme, and Open Problems.](https://arxiv.org/abs/2404.10255) *arXiv preprint arXiv:2404.10255*. 2024.

[Federated Class-Incremental Learning with New-Class Augmented Self-Distillation.](https://arxiv.org/abs/2401.00622) *arXiv preprint arXiv:2401.00622.* 2024.

[Knowledge Distillation in Federated Edge Learning: A Survey.](https://arxiv.org/abs/2301.05849) *arXiv preprint arXiv:2301.05849.* 2023.

## Thanks

We thank Zeju Li from Beijing University of Posts and Telecommunications, Sijie Cheng from Tsinghua University,
Tian Wen, Wen Wang and Yufeng Chen from Institute of Computing Technology, Chinese Academy of Sciences, Jinda
Lu from the University of Science and Technology of China for inspiring suggestions.  